Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.00029999999,0.0133563345,-3.6736055603881446,1498.5,-4.085082987944285
20000,1.4189384,0.00029999999,0.0023564114,-3.4161873728766556,1498.5714285714287,-2.0482896821839467
30000,1.4185921,0.00029999999,0.005015733,-3.588798700501294,1498.4285714285713,-2.352781961361567
40000,1.4185921,0.00029999999,0.014577304,-3.690557081827137,1498.5,-1.2854513781411308
50000,1.4185581,0.00029999999,-0.0314272,-3.4620927701325854,1498.5714285714287,-4.610182676996503
60000,1.4181665,0.00029999999,-0.033860378,-3.9581302555171924,1498.4285714285713,-4.627304434776306
